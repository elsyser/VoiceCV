{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = '../data/'\n",
    "\n",
    "TEXT_FILES_DIR = PATH_TO_DATA + 'Flickr8k_text/'\n",
    "IMAGES_DIR = PATH_TO_DATA + 'Flickr8k_Dataset/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding and formating the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000268201_693b08cb0e.jpg#0\tA child in a pink dress is climbing up a set of stairs in an entry way .\n",
      "1000268201_693b08cb0e.jpg#1\tA girl going into a wooden building .\n",
      "1000268201_693b08cb0e.jpg#2\tA little girl climbing into a wooden playhouse .\n",
      "1000268201_693b08cb0e.jpg#3\tA little girl climbing the stairs to her playhouse .\n",
      "1000268201_693b08cb0e.jpg#4\tA little girl in a pink dress going into a wooden cabin .\n",
      "1001773457_577c3a7d70.jpg#0\tA black dog and a spotted dog are fighting\n",
      "1001773457_577c3a7d70.jpg#1\tA black dog and a tri-colored dog playing with each other on the road .\n",
      "1001773457_577c3a7d70.jpg#2\tA black dog and a white dog with brown spots are staring at each other in the street .\n",
      "1001773457_577c3a7d70.jpg#3\tTwo dogs of different breeds looking at each other on the road .\n",
      "1001773457_577c3a7d70.jpg#4\tTwo dogs on pavement moving toward each other .\n"
     ]
    }
   ],
   "source": [
    "with open(TEXT_FILES_DIR + 'Flickr8k.token.txt', 'r') as flickr8_token:\n",
    "    raw_image_description = flickr8_token.read().split('\\n')[:-1]\n",
    "\n",
    "print('\\n'.join(raw_image_description[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict_image_descriptions(raw_image_description):\n",
    "    image_descriptions = dict()\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(raw_image_description):\n",
    "        img_name = raw_image_description[i].split('.')[0]\n",
    "        image_descriptions[img_name] = []\n",
    "        \n",
    "        while i < len(raw_image_description) and img_name == raw_image_description[i].split('.')[0]:\n",
    "            descr = raw_image_description[i].split('\\t')[1]\n",
    "            image_descriptions[img_name].append(descr)\n",
    "            i+=1\n",
    "            \n",
    "    return image_descriptions\n",
    "\n",
    "image_descriptions = get_dict_image_descriptions(raw_image_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A brown and white dog is running through the snow .',\n",
       " 'A dog is running in the snow',\n",
       " 'A dog running through snow .',\n",
       " 'a white and brown dog is running through a snow covered field .',\n",
       " 'The white and brown dog is running over the surface of the snow .']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_descriptions['101654506_8eb26cfb60']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(sentence):\n",
    "    # Tokenize\n",
    "    tokens = sentence.split()\n",
    "    \n",
    "    # Lower Case\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    \n",
    "    # Remove punct\n",
    "    for i in range(len(tokens)):\n",
    "        tokens[i] = ''.join([ch for ch in tokens[i] if ch not in punctuation])\n",
    "    \n",
    "    # Remove hanging chars\n",
    "    tokens = [token for token in tokens if (len(token) > 1 or token == 'a')]\n",
    "    \n",
    "    # Remove tokens with digits in it\n",
    "    tokens = [token for token in tokens if token.isalpha()]\n",
    "    \n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a hello are you'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean(\n",
    "    'A HellO! How12 are yoU>??'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_name, descriptions in image_descriptions.items():\n",
    "    image_descriptions[img_name] = [clean(descr) for descr in descriptions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a brown and white dog is running through the snow',\n",
       " 'a dog is running in the snow',\n",
       " 'a dog running through snow',\n",
       " 'a white and brown dog is running through a snow covered field',\n",
       " 'the white and brown dog is running over the surface of the snow']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_descriptions['101654506_8eb26cfb60']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Vocabulary size: 8764\n"
     ]
    }
   ],
   "source": [
    "vocabulary = set()\n",
    "\n",
    "for key in image_descriptions.keys():\n",
    "    [vocabulary.update(descr.split()) for descr in image_descriptions[key]]\n",
    "    \n",
    "print(f'Original Vocabulary size: {len(vocabulary)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add zero for zero-padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary.update('0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort the Vocabulary lexically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = sorted(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Idx and Idx2Word maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = dict([(list(vocabulary)[i], i) for i in range(len(vocabulary))])\n",
    "idx2word = dict([(i, list(vocabulary)[i]) for i in range(len(vocabulary))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2222"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx['dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dog'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2word[2222]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Description Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of descriptions: 40460\n"
     ]
    }
   ],
   "source": [
    "descriptions = []\n",
    "\n",
    "for key, val in image_descriptions.items():\n",
    "    for descr in val:\n",
    "        descriptions.append(descr)\n",
    "\n",
    "print(f'Total number of descriptions: {len(descriptions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longes description:\n",
      "\n",
      "\"an africanamerican man wearing a green sweatshirt and blue vest is holding up dollar bills in front of his face while standing on a busy sidewalk in front of a group of men playing instruments\"\n"
     ]
    }
   ],
   "source": [
    "longets_description = max(descriptions, key=lambda x: len(x.split()))\n",
    "\n",
    "print(f'Longes description:\\n\\n\"{longets_description}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Description Length: 35\n"
     ]
    }
   ],
   "source": [
    "max_description_length = len(longets_description.split())\n",
    "\n",
    "print(f'Max Description Length: {max_description_length}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Dev/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_set_images(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        img_names = f.read().split('\\n')[:-1]\n",
    "        \n",
    "    img_names = [name.split('.')[0] for name in img_names]\n",
    "    return img_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 6000\n",
      "Dev size: 1000\n",
      "Test size: 1000\n"
     ]
    }
   ],
   "source": [
    "train_images = load_set_images(TEXT_FILES_DIR + 'Flickr_8k.trainImages.txt')\n",
    "dev_images = load_set_images(TEXT_FILES_DIR + 'Flickr_8k.devImages.txt')\n",
    "test_images = load_set_images(TEXT_FILES_DIR + 'Flickr_8k.testImages.txt')\n",
    "\n",
    "print(f'Train size: {len(train_images)}')\n",
    "print(f'Dev size: {len(dev_images)}')\n",
    "print(f'Test size: {len(test_images)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_image_descriptions_set(set_images):\n",
    "    image_descriptions_set = dict()\n",
    "    \n",
    "    for img_name in set_images:\n",
    "        image_descriptions_set[img_name] = []\n",
    "        descriptions = image_descriptions[img_name]\n",
    "        \n",
    "        for descr in descriptions:\n",
    "            image_descriptions_set[img_name].append(\n",
    "                '<SOS> ' + descr + ' <EOS>'\n",
    "            )\n",
    "    \n",
    "    return image_descriptions_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 6000\n",
      "Dev size: 1000\n",
      "Test size: 1000\n"
     ]
    }
   ],
   "source": [
    "train_image_descriptions = init_image_descriptions_set(train_images)\n",
    "dev_image_descriptions = init_image_descriptions_set(dev_images)\n",
    "test_image_descriptions = init_image_descriptions_set(test_images)\n",
    "\n",
    "print(f'Train size: {len(train_image_descriptions)}')\n",
    "print(f'Dev size: {len(dev_image_descriptions)}')\n",
    "print(f'Test size: {len(test_image_descriptions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<SOS> a black dog is running after a white dog in the snow <EOS>',\n",
       " '<SOS> black dog chasing brown dog through snow <EOS>',\n",
       " '<SOS> two dogs chase each other across the snowy ground <EOS>',\n",
       " '<SOS> two dogs play together in the snow <EOS>',\n",
       " '<SOS> two dogs running through a low lying body of water <EOS>']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image_descriptions['2513260012_03d33305cf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`<SOS>` = **Start Of Sequence** <br>\n",
    "`<EOS>` = **End Of Sequence** <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
